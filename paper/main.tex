%% 
%% Copyright 2007-2025 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.3 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references

\documentclass[preprint,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsmath package provides various useful equation environments.
\usepackage{amsmath}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}
\usepackage{subcaption} % Put this in the preamble
%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

\usepackage{hyperref}
%
%\usepackage{wrapfig}
%\usepackage{graphicx}

\journal{Energy and AI}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \affiliation for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%% \fntext[label3]{}

\title{Mixed Integer Stochastic Optimization of relative Position of two Wind Turbines using using Neural Network based Constraint Learning} %% Article title

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \affiliation[label1]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%%
%% \affiliation[label2]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}

\author{Simon Schmetz} %% Author name

%% Author affiliation
\affiliation{organization={Universidad Carlos III de Madrid},%Department and Organization
            addressline={test}, 
            city={test},
            postcode={test}, 
            state={test},
            country={test}}


%% Use \subsubsection, \paragraph, \subparagraph commands to 
%% start 3rd, 4th and 5th level sections.
%% Refer following link for more details.
%% https://en.wikibooks.org/wiki/LaTeX/Document_Structure#Sectioning_commands


%% Abstract
\begin{abstract}

The following paper combines Linear Optimization with Constraint Learning to optimize wind turbine placement for maximum performance in a predefined area under randomly distributed wind. A Neural Network is trained on simulated data to model the impact of turbine positioning on power output. This model is integrated as a constraint in a linear optimization problem, and the problem evaluated for a current state-of-the-art wind farm configuration.

\end{abstract}

%%Graphical abstract
\begin{graphicalabstract}
%\includegraphics{grabs}
\end{graphicalabstract}

%%Research highlights
\begin{highlights}
\item Research highlight 1
\item Research highlight 2
\end{highlights}

%% Keywords
\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
Constraint Learning \sep Mixed Integer Optimization \sep Machine Learning \sep Neural Networks \sep Wind Farm Optimization

%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

%% Add \usepackage{lineno} before \begin{document} and uncomment 
%% following line to enable line numbers
%% \linenumbers

%% main text
%%

%% Use \section commands to start a section


\section{Introduction}\label{chapter:introduction}


With the clean energy transition currently taking place in Europe with ambitious targets for 2030 and beyond \cite{EU_RE_Targets_2023}, wind energy is playing a central role in that transition and expected to rise to 50 \% in the EU energy mix. \cite{ConsiliumEU_Harnessing_Wind_Power_2024}
With wind energy thus expected to become one of the main contributers to the EU's energy production and large potentials identified for both onshore and offshore parks \cite{EEA_Wind_Energy_Potential_2009}, attempts to optimize all parameters of windparks that result in even minor power efficeny improvement can be expected to yield significant returns in absolute power due to the scale of future wind energy production. 

Within the main wind energy challanges lies the problem of optimizing the layout of wind farms. Here, the main goal is to reduce the negative impact that wake effects between wind turbines have on overall power generation, with yield reduction of up to $15\%$  mainly due to reduced wind speeds in wake regions. Optimizing the farm for overall minimal wake exposure between wind turbines can thus potentially significantly increase the power output. \cite{hou_review_2019} \cite{KIM2024123383} 

In practice, the problem reduces to placing wind turbines within a predefined zone, subject to the wind conditions as shown in Figure \ref{fig:intro_plot}. These wind conditions can be assumed to be deterministic or (more accurately) random variables, by considering probability distributions for variables like wind direction and wind speed.


\begin{figure}[h] 
	\centering
	\includegraphics[width=0.6\textwidth]{../figures/introduction/intro_plot.png} 
	\caption{Optimizing the total power output of a farm reduces to placing wind turbines within a set space for the farm, subject to the wind conditions at the given location}
	\label{fig:intro_plot}
\end{figure}


%
%\begin{wrapfigure}{r}{0.5\textwidth}
%	\centering
%	\includegraphics[width=0.48\textwidth]{../figures/introduction/intro_plot.png}
%	\caption{Optimizing the total power output of a farm reduces to placing wind turbines within a set space for the farm, subject to the wind conditions at the given location.}
%	\label{fig:intro_plot}
%\end{wrapfigure}


This thesis is dedicated to a new approach for optimizing the placement of a fixed number of wind turbines in a predefined space, beginning with the two-turbine problem, the problem of optimally placing two turbines relative to each other. To solve this optimization problem, an extension to the Pyomo Python library is used, which allows the embedding of Neural Networks into the optimization problem as a set of constraints \cite{ALCANTARA2023120895}. This extension allows the modelling of the effects of wind turbine placement relative to each other on power production. Introducing this model into the problem then allows for the optimization of overall power production across all wind turbines in the wind park.

To create a model optimally fit to the needs of the optimization problem, the model is trained on data specifically generated with the \href{https://www.nrel.gov/wind/floris.html}{FLORIS} \cite{nrel_floris} wind farm simulation tool  for optimal coverage of the optimizations parameter space. To simplify the problem, the surface below the turbines is assumed to be perfectly flat and an equal wind speed is assumed along the entire height of the turbines. Solving the problem can be seperated into two main Steps:

\begin{enumerate}
	\item \textit{Farm Power Model:} Generation of simulation data covering the parameter space and training a Neural Network model with power generation as output
	\item \textit{Optimization:} Setting up optimization problem, embedding of power model and solving
\end{enumerate}

This thesis is structured according to these two main steps, with a brief review of the state-of-the-art in wind turbine placement optimization and constraint learning beforehand. 

%% Use \subsection commands to start a subsection.

\section{Literature Review}\label{chapter:state_of_the_art}

Since the arrival of large-scale wind turbine farm operations as part of energy infrastructure, optimizing the positioning of the individual wind turbines relative to each other to mitigate wake effects and maximize the total power output is the subject of scientific investigation. As this Thesis is an attempt to apply a novel constraint learning method introduced in \cite{ALCANTARA2023120895} to the optimization of wind farm layouts, the following state-of-the-art is split into two pieces:  The first investigates the current relevant publications of wind farm optimization and the second one presents a brief introduction into recent developments in the field of constraint learning. 

\subsection{Optimization of Wind Farm Layouts}

As discussed in the introduction, one of the main goals in the optimization of wind farm layouts is to reduce the negative impact of wake effects between wind turbines \cite{KIM2024123383}. Historically, rule of thumb approaches were used by setting up the layout as a grid  with the distance between wind turbines, with spacing in the dominant wind direction between 8 and 12 times the turbine rotor diameter and spacing perpendicular to the dominant wind direction 4 to 6 times the turbine rotor diameter \cite{AZLAN2021110047} \cite{hou_review_2019}.

These methods have evolved to with pursuing the goal of maximizing the Annual Energy Production (AEP) of wind farms in the context of stochastic optimization as done in \cite{Sinner_2024} \cite{KIM2024123383}. 

The core of any of the most recent optimizations models is a wake model, which becomes part of the objective function to represent the wake effects on power output. These models can be categorized as \cite{WANG2024118508}: 

\begin{enumerate}
	\item Experimental Methods
	\item Numerical modeling
	\item Analytical/semi-empirical modeling
	\item Data-driven modeling
\end{enumerate}

While experimental methods and numerical models might be the most precise models available for wake modeling, one of the challenges that come with the optimization is that the model has to be able to be introduced into the current state-of-the-art solvers as part of an objective function, leading to the prevalent use of analytical wake models like the Gaussian wake model and the 3D wake model  \cite{WANG2024118508}. With advancements in Machine Learning, the field of data-driven modeling is meanwhile expanding, with successful attempts in introducing Neural Networks and other Machine Learning frameworks into optimizations of wind farm layouts. Generally, either experimental data or data from numerical modeling (more prevalent) is used to train  a chosen model type. The resulting model is then introduced into the optimization problem, as done in \cite{YANG2023119240} \cite{wes-9-869-2024} \cite{TI2020114025} \cite{TI2021618}. 

\subsection{Constraint Learning}

The term Constraint Learning, defined as "finding a set of constraints, a constraint theory, that satisfies a given dataset" in \cite{de2018learning}, is the intersection of machine learning and optimization or more in practical terms, the introduction of machine learning models into optimization problems as constraints. As the in Machine Learnin the models learn from a given data set, the constraints resulting from such a model are equally learned. \cite{de2018learning} 

For this Thesis specifically, we consider the uncertainty aware constraint learning method of decomposing a neural network into a set of mixed-integer linear constraints  \cite{ALCANTARA2023120895} \cite{ALCANTARA2025127876}. Similar approaches of embedding machine learning models into optimization problems have been taken for Decision Trees and Random Forests in \cite{preprintBonfiettiEmbeddDecisionTrees} or for Neural Networks(without integer variables required), as done in \cite{dealba2024reformulationembeddingneuralnetwork}. A survey performed by Fajemisin et al.\cite{FAJEMISIN20241} shows how the field is currently emerging with an increase in publications in recent years and most publications revolving around the Embedding of Neural Networks and Decision Trees/Random Forests.



\section{Farm Power Model}\label{chapter:power_model}

The first central component in optimizing the wind farm layout is to generate a data-driven surrogate Model that can be introduced into the optimization problem and solved by a solver. As detailed in the introduction, the goal is to use the distCL extension \cite{alcantara_ruiz_distcl_2022_git} to the Pyomo Python package, using a small Neural Network as a surrogate model. The following chapter documents the steps taken to generate such a model. 
To train a Neural Network, data is required that covers the parameter space of the optimization to prevent extrapolation by the model. Therefore, the chapter starts by explaining how the open-source wind farm simulation tool \href{https://www.nrel.gov/wind/floris.html}{FLORIS} \cite{nrel_floris} was used to generate a datase. Then, the fundamentals of Neural Network architecture and training are briefly introduced, before the pipeline that yields the final model is presented.


\subsection{Data Source}

The power output of wind turbines and wind farms as a whole is fundamentally connected to the aerodynamic conditions in the airflow every wind turbine experiences, with wind speed as the biggest factor relevant to how much power a wind turbine can generate. The main effect reducing the power generated by a wind turbine is to be positioned in the wake downwind of another turbine. This power reduction is primarily a result of the reduction in windspeed joined with the increased turbulence in the wake airflow \cite{KIRANOUDIS1997439}. Moving further downstream of a wind turbine, the wake gradually mixes with the outer airflow and thus again increases windspeed until the entire airflow reaches a new homogeneous air speed \cite{MAGNUSSON1999169}. Thus, even if a wind turbine is positioned in the wake of another wind turbine, the greater the distance between the two, the less the second wind turbine is affected. Ideally, wind turbines are not positioned in the wake of other wind turbines at all. 


With the overall goal of creating a model on how the interaction between wind turbines (induced by the wake) is related to the wind turbines relative positioning to each other and the wind conditions as input to an optimization model, a tailor-made dataset from simulation results is the easiest way to ensure that the data fits the use case well. After investigating two Python-based open source wind farm simulation tools FLORIS (\href{https://www.nrel.gov/wind/floris}{FLORIS official website} \cite{nrel_floris_web}) and PyWake (\href{https://topfarm.pages.windenergy.dtu.dk/PyWake/}{PyWake Documentation} \cite{dtu_pywake_2025}), FLORIS was chosen due to its apparent ease of use. 

 As turbine type, an IEA 10-MW is used for data generation due to its repeated use as a baseline turbine in other scientific works like \cite{Madsen2022} and \cite{Kainz2024IEA} and a more exact technical specification of the turbine can be found in \cite{Bortolotti2019}. The configurations of the specific dataset generated are chosen for the individual optimization problem formulations as detailed in Chapter \ref{section:optimization}.


\subsection{Introduction to Neural Networks} \label{sec:modelling}

To model the relationship between the attributes of an incoming airflow to a wind turbine and the output generated by the same wind turbine, many surrogate models could be chosen. As the model generated for this thesis is created to be then embedded into the Pyomo extension as explaind in Chapter \ref{chapter:introduction}, the model has to be compatible with said extension. That is why the model chosen is a simple neural network with a limited number of hidden layers and nodes, as large models increase the number of constraints required to decompose the model. 

Neural Networks represent Graph Networks consisting of function blocks as the nodes, in the case of Neural Networks called "perceptrons" (or Neurons as a more general term) and arcs which correspond to the inputs/outputs of a given perceptron. In simple words, the inputs to the Neurons are summed up and introduced as an argument into a function $f()$, which yields an output $y$ of the given perceptron. These Neurons are organized in layers, which correspond to the row-type structure Neural Networks are usually represented in and each perceptron of one layer is connected to every other perceptron of the following layer. The following layer, in this case, means in the direction of flow, in visualizations usually from left to right. The arcs thus correspond to a single number, and the Neurons to the action of summing up all inputs and then applying the unspecified function $f()$ to generate an output. This process is repeated for all Neurons in the network, with the first layer of the network taking as input the values of the given data features (the input values to the model) and the last layer producing outputs corresponding to the output value(s) of the model. The number of Neurons in this first and last layer corresponds to the task of the Neural Network. If the goal is to identify handwritten numbers 1-9 from 50x50 pixel images, the input layer might have 50x50 Neurons for the value of each pixel, and the output as 9 layers with the output value of each of those last perceptrons representing how much the network "thinks" the given image shows the corresponding numbers 1-9. A schematic of this architecture is given in Figure \ref{fig:neural_network_architecture}.

\begin{figure}[h] 
	\centering
	\includegraphics[width=0.6\textwidth]{../figures/modelling/neural_network_concept.png} % file name without extension
	\caption{Schematic of Neural Network Architecture}
	\label{fig:neural_network_architecture}
\end{figure}

As shown in Figure \ref{fig:neuron_calculations} the output of a Neuron is  the output $y$ is generated by summing up the inputs $x$ multiplied by a corresponding weight $w$ together with a bias $b$ and introducing this summation as an argument into an activation function $f()$. In this process, the weights $w$ represent a weight to give importance to the individual inputs and the bias $b$ serves to set a minimum output value that will always be reached, regardless of the inputs. 

\begin{figure}[h] 
	\centering
	\includegraphics[width=0.6\textwidth]{../figures/modelling/perceptron_concept.png} % file name without extension
	\caption{The output of a neuron is generated by applying the activation function to the sum as the weighted inputs $w_ix_i$ and the bias of the neuron $b$}
	\label{fig:neuron_calculations}
\end{figure}

The function $f()$ is called the activation function, as in its simplest form it represents a step function that decides if a neuron activates or not, e.g., takes the binary values ${0,1}$ for a given threshold. Contrary to the human brain, where neurons are indeed binary, most Neural Networks resort to an activation function whose outputs are not binary but deliver continuous values between $0$ and $1$ to avoid the boundary issues that occur with thresholds. The most common function used in place of a step function is the sigmoid function, which roughly corresponds to a continuous version of the step function, with $\sigma(x) \approx 1$ for $x \to \infty$ and $\sigma(x) \approx 0$ for $x \to -\infty$.


\[
\sigma(x) = \frac{1}{1 + e^{-x}}
\]

This relationship also becomes apparent when plotting both of those functions over each other, as shown in Figure \ref{fig:activation_functions}. 
An alternative to the sigmoid as activation function is the Rectified Linear Unit (ReLu) function, or in simple words, the maximum function, defined as

\[
\text{ReLU}(x) = \max(0, x) = 
\begin{cases}
	0 & \text{if } x < 0, \\
	x & \text{if } x \geq 0.
\end{cases}
\]

The main general applicable benefit of the ReLu function is that it has a constant, non-vanishing gradient for both directions (see Figure \ref{fig:activation_functions}), leading to better gradient propagation, an attribute that is relevant in the context of the backpropagation briefly discussed at the end of the Section. \cite{preprintReLuGlorot}
Beyond this, the ReLu function allows for embedding the Neural Network into a optimization problem, as will be discussed in Section \ref{sec:constraint_learning}.

\begin{figure}[h] 
	\centering
	\includegraphics[width=0.45\textwidth]{../figures/modelling/activation_functions.png} % file name without extension
	\caption{The Sigmoid Function being close to the Step Function without being as sensitive to slight changes in $x$ due to its continuity. Alternatively, the Rectified Linear Unit function (ReLu) can be used as activation function. }
	\label{fig:activation_functions}
\end{figure}

\cite{nielsen2015neuralChap1}


The training of the Neural Network thus corresponds to adjusting the weights and biases in a way that minimizes the chosen loss function. The algorithm most commonly used for this is called \textit{Backpropagation}. \cite{nielsen2015neuralChap1}
The algorithm to do so corresponds to: 

\begin{enumerate}
	\item Introduce Training Data into the Neural Network
	\item Evaluate the Loss Function for the Training Points (with small random values for weights and biases for the first iteration) and evaluate the gradients of the Loss function for the gradients of the individual weights and biases 
	\item Update the weights and biases according to a learning rate $\rho$ weighted by the specific weight or biases gradient
	\item Repeat process $n$ Epochs, with one Epoch being the algorithm passing through all training points once
\end{enumerate}



\section{Stochastic Optimization and Constraint Learning}\label{section:optimization}

With the theoretical and pratical foundations of the model of farm/turbine power established, the following section treats the embedding of the trained model(s)  into a deterministic/stochastic optimization problem. The underlying theory of optimization under uncertainty and constraint learning is introduced before the actual optimization problems for the two turbine optimization problem are defined, the required models trained, and the results discussed.


\subsection{Optimization under Uncertainty} \label{subsec:opti_under_uncertainty}

Like in many areas, knowledge about the uncertainty associated with certain variables can change decisions in which these variables underlying uncertainty plays a part. For example, while optimizing anything from next year's crop to tomorrow's energy pricing, the field of Stochastic Programming is occupied with finding methods that allow for introducing these uncertainties into optimization problems.

One way to approach these uncertainties is to split the problem into scenarios. A bakery, for example, has to decide on how many Baguettes to bake for the next day to maximize its profit. Baking too few Baguettes will lead to missing out on potential sales, while baking too many baguettes will mean that the demand is fulfilled, but the money invested in the excess number of baguettes is lost. Assuming the mean number of baguettes bought every day is $1000$, the price to buy a baguette is $1 €$ and the cost to produce a baguette is $0,2 €$ the classical approach to solving such a problem would be by the following formulation \footnote{$x$ non-negative}: 


\begin{align*}
	\max_{x} \quad \left( 1.00 \cdot \min(x,1000) - 0.20 \cdot x \right)
\end{align*}


To represent uncertainty, additional scenarios of the demand being $10\%$ lower ($900$ Baguettes) and $10\%$ higher ($1100$ Baguettes) can be added. Assuming that the mean demand has a $50\%$ probability of occurring, the $10\%$ demand increases a $20\%$ probability and the $10\%$ decrease a $30\%$  probability, the problem can be modified to maximize the expected profit across these three scenarios by the formulation

\begin{align*}
	\max_{x} \quad & 0.5 \cdot \left(1.00 \cdot \min(x,1000) - 0.20 \cdot x \right) \\
	&+ 0.3 \cdot \left(1.00 \cdot \min(x,900) - 0.20 \cdot x\right) \\
	&+ 0.2 \cdot \left(1.00 \cdot \min(x,1100) - 0.20 \cdot x\right)
\end{align*}

Assuming only these three scenarios are possible, the result from this optimization problem would be the Expected profit and how many Baguettes are the optimal number of Baguettes to yield the maximum Expected profit across all scenarios. This would be optimal assuming there is no more information about the next day's demand, meaning that by using this approach, the total profit over a long time would be maximal. In case there is more information regarding the next day's demand, the probabilities that give the weights in this optimization might shift, with one scenario potentially reaching probability $100\%$ if there were to be absolute certainty that the next day's demand would be, for example, $1100$ baguettes. As having such exact information is very rare, the best solution will be in most cases to maximize the profit Expectation. 

The obvious connection to conventional statistical analysis is that the demand is a random variable that can take multiple values, in this case, we assumed it to be a discrete random variable $Y$ with support ${900,1000,1100}$ even though in real-world applications the demand of baguettes will move somewhere between $[0,\infty]$. Finding the Expectation for such a discrete random variable can be done as 

\[
\mathbb{E}[X] = \sum_{i} x_i \cdot \mathbb{P}(X = x_i) = \sum_{i} x_i p_i
\]

or for continuous random variables  

\[
\mathbb{E}[X] = \int_{-\infty}^{\infty} x \cdot f_X(x) \, dx
\]

Using these two expressions, optimization problems can thus be formulated to optimize the Expectation of objective functions containing random variables. \cite{BirgeLouveauxStochasticProgramming}


\subsection{Constraint Learning} \label{sec:constraint_learning}

Constraint learning refers to introducing a model that has learned relationships between certain variables from data into an optimization problem. In the case of constraint learning, the model is more specifically introduced into an optimization problem as a set of constraints. As many real-life relationships are dificult to represent by a simple analytical function, introducing machine learning models to optimization problems opens up many new possibilities \cite{FAJEMISIN20241}.

In the case of Neural Networks, one way of introducing a Neural Network as a constraint into an optimization problem is by recognizing that when using the Rectifier Linear Unit (ReLu) Function as activation function with the (linear) sum of neuron bias and weighted inputs $\tilde{v}_i^\ell$ being the function argument


\begin{equation}
	v_i^\ell = \max(0, \tilde{v}_i^\ell) = \max(0,  b_i^\ell + \sum_j w_{ij}^\ell v_j^{\ell - 1})
\end{equation}


the function can be rewritten as the following constraints 

\begin{align}
	v_i^\ell &\geq \tilde{v}_i^\ell \\
	v_i^\ell &\leq \tilde{v}_i^\ell - M^{\text{low}}(1 - j_i) \\
	v_i^\ell &\leq M^{\text{up}} j_i
\end{align}

with $j_i \in \{0,1\}$ a integer variable such that

\begin{align}
	j_i =
	\begin{cases}
		0 & \text{if } \tilde{v}_i^\ell < 0 \\
		1 & \text{if } \tilde{v}_i^\ell > 0
	\end{cases}
\end{align}

This decomposition allows for introducing a Neural Network into an optimization problem by decomposing it into the shown set of mixed-integer linear constraints \cite{ALCANTARA2023120895}.


\subsection{Quantile Discretization of Wind Direction Distribution } \label{subsubsection: discretization}

A problem that occours with the discrete scenarios introduced in Section \ref{subsec:opti_under_uncertainty} is that such scenarios like in the case of wind directions might leave large gaps in areas which in the continious distribution would experience a high probability density. This issue can be partially solved by discretizing not with a constant step length but based on the quantiles of the distribution. The discretization can be instead performed not by a constant length of the discretization steps, but by a constant probability within a chosen number of quantiles. For each quantile individually, the mean is then calculated and the resulting expected values for the quantile are taken as discretization steps. This approach, when used for the same Normal distribution with mean 270° and standard deviation 5°, fixing the scenario/quantile count to 7, yields the discretization shown in Figure \ref{fig:wind_dist_opti_quantiles}. 

\begin{figure}[h] 
	\centering
	\includegraphics[width=0.8\textwidth]{../figures/optimization/wind_dist_opti_quantiles.png} 
	\caption{Quantile based discretization of Normal mean 270°,  standard deviation 5°, disrcetized into 7 scenarios with equal probability for scenario and the scenario angle corresponding to the expected value for the quantile }
	\label{fig:wind_dist_opti_quantiles}
\end{figure} 

Using this distribution, the expected power distribution changes for the corresponding scenarios/quantiles, with the space left between scenarios proportional to the probability density. When considering the previous approach to stochastic optimization, the number of scenarios that can be introduced into the problem has now become the main limitation. The following subsection provides an alternative set up that allows for a greater number of scenarios.

\section{The Two Turbine Problem}

Optimizing the positioning of two wind turbines can be expressed as optimizing the relative position of a second wind turbine $T_2$ to a fixed first turbine $T_1$, defined by the relative distances $\Delta x$ and  $\Delta y$. Both  $\Delta x$ and  $\Delta y$ are constrained by minimum distance $\Delta_{min}$ to  $T_2$ and maximum distances $\Delta x_{max}$/$\Delta y_{max}$ to make the problem bounded. 
This problem can be visualized as shown in Figure \ref{fig:two_turbine_problem}.

\begin{figure}[h] 
	\centering
	\includegraphics[width=0.6\textwidth]{../figures/optimization/two_turbine_problem_schematic.png} % file name without extension
	\caption{Optimizing the relative position $\Delta x$/$\Delta y$ of a second wind turbine $T_2$ to a fixed first turbine $T_2$, constrained by minimum distance $d_{min}$ to  $T_1$ and maximum distances $\Delta x_{max}$/$\Delta y_{max}$}
	\label{fig:two_turbine_problem}
\end{figure}

The objective function to be optimized is the total power generation, e.g. the sum of power generated by both turbines. This objective is a function of both the position of the wind turbine as well as of the wind conditions like wind direction and wind speed. 

$$
f_{total Power}(x,y,\text{windspeed},\text{wind direction}, \text{(...)})
$$

Different from the geographic coordinates, the wind condition parameters like windspeed are inherently not deterministic and follow distributions like the normal distribution as shown in Figure \ref{fig:wind_dist}.

\begin{figure}[h] 
	\centering
	\includegraphics[width=0.9\textwidth]{../figures/optimization/wind_dist.png} % file name without extension
	\caption{Histogram and Polar Plot across radiants for a normally distributed wind direction probability density function with mean West}
	\label{fig:wind_dist}
\end{figure}

The two main challenges of the optimization of the two-turbine problem are thus: 

\begin{enumerate}
	\item Introduce the complex relationship between turbine position, wind conditions, and power output into the optimization problem
	\item Introduce the non-deterministic nature of wind conditions into the optimization problem
\end{enumerate}

The first of these challenges is tackled by applying the Neural Network models discussed in Section \ref{sec:modelling} and introducing them into the optimization problem via constraint learning as described in Section \ref{sec:constraint_learning}. For the second problem, two approaches probabilistic approaches are explored in the following subsections.

\subsection{Stochastic Optimization: Wind distribution indipendent Neural Network} \label{sec:stoch_opti_1}

The first stochastic formulation of the problem aims to set up the Neural Network in such a way, that makes it indipendent from the distribution of wind condition variables that is then used to generate scenarios for the calculation of the expectation. To do so, the objective function is a probability weighted sum, that represents the expected power generated by the farm. The Neural Network thus  has to be able to predict the power output for a given turbine 2 location, taking into account the wind condition parameters (for example like direction and speed) at a given location. The problem is formulated as follows: 

\begin{align}
	\max_{\mathbf{x}, \mathbf{y}} &  \sum_{i=1}^{n} f_{Power,\text{NN}}(\Delta x, \Delta y, \text{wind condition})\cdot p_{n,\text{wind condtion combination}} \\
	\text{s.t.} \quad 
	&  \Delta x \leq X_{\max} \\
	&  \Delta y \leq Y_{\max} \\
	& \sqrt{(\Delta x)^2 + (\Delta y)^2} \geq d_{\min}
\end{align}

Where:
\begin{itemize}
	\item \( (\Delta x, \Delta y) \) are the relative distances of the two turbines,
	\item \( f_{Power, \text{NN}}(\Delta x, \Delta y)\) is a deterministic neural network  approximating the total power output for turbine positions and wind conditions
	\item \(  X_{\max}, Y_{\max} \) define the maximal distance the two turbines can be placed apart
	\item \( d_{\min} \) is the minimum distance between the two turbines
	\item \(p_{n, \text{wind condtion combination}}\) is the probability corresponding to each of the scenarios
	\item \( n \) is the index of the discretized possible combinations of wind conditions 
\end{itemize}

The following section will first treat the univariate case of only wind direction being random, while wind speed and turbolence intensity remain constants. 

The Notebook belonging to this formulation can be found in \href{https://github.com/schmeti/uc3m_TFM_wind_farm_optimization_codebase/blob/main/Windfarm_power_modelling/0_two_turbine_problem_constrLearn_probweighted.ipynb}{Stochastic optimization with farm power NN Fomulation Notebook} \cite{schmetz2025twoturbine_stoch1}

\subsubsection{Modelling}

We begin by finding a fitting Neural Network model that can be embedded into the optimization problem. To do so, we again define the parameter space, this time with wind direction being variable and set up in a grid with step length of 10°. The full parameter grid is defined in Table \ref{tab:val_prob_data}

\begin{table}[ht]
	\centering
	\caption{Value Ranges for Probabilistic Two Turbine Problem Data Set}
	\begin{tabular}{|l|c|c|c|}
		\hline
		\textbf{Variable} & \textbf{Const/Variable} & \textbf{Value} & \textbf{$Steplength$}\\
		\hline
		$\Delta x_{\text{turb2}}$ & Variable & [0, 5000] m & 50 m\\
		$\Delta y_{\text{turb2}}$ & Variable & [0, 500] m  & 50 m\\
		wind\_speed & Constant & 8 m/s & -\\
		wind\_direction & Variable & [180°, 270°]& 10° \\
		turbulence\_intensity & Constant & 0.06 & - \\
		\hline
	\end{tabular}
	\label{tab:val_prob_data}
\end{table}

We then proceed to hyperparameter tuning of the model. As apparent in Figure \ref{fig:determ_nn_opti}, the performance appears to flatline for models with or more than 2 layers and with or more than 50 nodes, yielding similar performance. To minimize the number of nodes, we thus proceed with the initial model configuration $\text{NN}(5\,{-}\,50^{\times2}\,{-}\,1)$ for the following optimization.


\begin{figure}[h] 
	\centering
	\includegraphics[width=0.62\textwidth]{../figures/optimization/prob_nn_opti.png} 
	\caption{Grid Search results for a Neural Network configuration to predict for data with variable wind direction, showing similar performance for models of layers greater or equal than two, starting at 50 or more nodes}
	\label{fig:determ_nn_opti}
\end{figure}


With a model chosen, we investigate its performance and find that while visually the shape of the wake generally appears to fit, the deviation in percent shows greater deviation, especially at greater distances away from Turbine 1 for the case of wind direction 260°, as shown in Figure \ref{fig:prob_model_colormap}. The model appears to also show some artifacts, with the most notable being the highest values in parallel to the wake right at the borders of the wake flow itself.

%\begin{figure}[h] 
%	\centering
%	\includegraphics[width=1\textwidth]{../figures/optimization/prob_model_colormap.png} 
%	\caption{A heatmap of total generated farm power for a wind direction of 260° with datapoints and linear interpolation in between. Plot 1 shows the raw data, plot 2 the predictions of the $\text{NN}(5\,{-}\,50^{\times2}\,{-}\,1)$, plot 3 the percentage difference between training points and predictions}
%	\label{fig:prob_model_colormap}
%\end{figure}

Having observed the deviation described above, another layer is added to the model in an attempt to prevent the previous behaviour. The resulting configuration $\text{NN}(5\,{-}\,50^{\times3}\,{-}\,1)$ improved the previous models weaknesses in that respect as can be seen in Figure \ref{fig:prob_model_colormap_2}, which is why \textit{the final model choosen for the optimization is  $\text{NN}(5\,{-}\,50^{\times3}\,{-}\,1)$}
%
%\begin{figure}[h] 
%	\centering
%	\includegraphics[width=1\textwidth]{../figures/optimization/prob_model_colormap_2.png} 
%	\caption{A heatmap of total generated farm power for a wind direction of 260° with datapoints and linear interpolation in between. Plot 1 shows the raw data, plot 2 the predictions of the $\text{NN}(5\,{-}\,50^{\times3}\,{-}\,1)$, plot 3 the percentage difference between training points and predictions, overall showing improved }
%	\label{fig:prob_model_colormap_2}
%\end{figure}




\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{../figures/optimization/prob_model_colormap.png}
		\caption{Predictions of $\text{NN}(5\,{-}\,50^{\times2}\,{-}\,1)$}
		\label{fig:prob_model_colormap}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{../figures/optimization/prob_model_colormap_2.png}
		\caption{Predictions of $\text{NN}(5\,{-}\,50^{\times3}\,{-}\,1)$}
		\label{fig:prob_model_colormap_2}
	\end{subfigure}
	\caption{Comparison of model predictions: the left with two hidden layers, the right with three, showing reduced deviation in the final model.}
	\label{fig:prob_model_comparison}
\end{figure}


While increasing the size of the Neural Network might further reduce the deviations across wind directions and for the individual wind directions, it is restricted by the solvability of the optimization problem. While there is no exact threshold, the solving time of the mixed integer problem that results from the embedding of the Neural Network increases roughly exponentially by adding Neurons to the Network and therefore adding binary variables to the problem. The shown model is deemed sufficient because of that trade-off.

For optimization purposes, the individual power per wind direction becomes less relevant, as the power outputs are weighted by their probability of occurring. 
To do so, first the probability distribution of the wind directions has to be defined, like the Normal distribution with mean 270° and standard deviation of 10° shown in Figure \ref{fig:wind_dist_opti}. To calculate the expectation for the retized parameter space using the trained model, this distribution itself has to be discretized in line with the initial parameter space defintion, which in this case is done in 10° steps. 


\begin{figure}[h] 
	\centering
	\includegraphics[width=0.6\textwidth]{../figures/optimization/wind_dist_opti.png} 
	\caption{Discrete Wind Direction Probability Distribution with mean 270° and standard deviation 5°, discretized in intervals of 10° }
	\label{fig:wind_dist_opti}
\end{figure}


Using this distribution, the expected power for the ranges of x and y coordinates can thus now be calculated by aggregating the powers for the different wind directions as a sum weighted by probability to yield the expected farm power generated at the specific coordinate. By evaluating the expected farm power both for the training data as well as for predictions for the training data, we can again compare the results and deviations as done in Figure \ref{fig:prob_expectation}. The directions with a probability greater than are shown as lines and their impact on the distribution of expected farm power visibel.

\begin{figure}[h] 
	\centering
	\includegraphics[width=1\textwidth]{../figures/optimization/prob_expectation.png} 
	\caption{Distribution of Expectation of Farm power from a discretized Normal distribution with mean 260° and standard deviation 10° with steplength 10°}
	\label{fig:prob_expectation}
\end{figure}


The normal distribution is used in this thesis as a placeholder for proof-of-concept purposes. In a practical application, the real wind distribution would have to be evaluated at the specific location of the wind farm. 

\subsubsection{Optimization}

With the model set up, solving the stochastic optimization problem for a maximum expected farm power output can be attempted. In the case of optimization, the problem is limited to three scenarios due to the computational constraints due to the size of the problem. A normal distribution with a mean of 270° and  a standard deviation of 5° was therefore used as the wind direction distribution, yielding three scenarios (260°,270°,280°).

The Neural Network and the wind direction distribution are introduced into pyomo to find a global maximum. As previously, a range of optima exists, with Poyomo choosing among this area, as seen in Figure \ref{fig:prob_data_lininter}. More specifically in this case, the area close to the wake had been shown to predict higher values than in the simulations by the model (see Figure \ref{fig:prob_model_colormap_2}), showing the optimization to find the global maximum within the provided Neural Network. 

\begin{figure}[h] 
	\centering
	\includegraphics[width=1\textwidth]{../figures/optimization/prob_data_lininter.png} 
	\caption{}
	\label{fig:prob_data_lininter}
\end{figure}

Like before, it is possible to visually find that there is a large range of more or less equally optimal points, with the few scenarios not covering the space appropriately. This leads to seemingly optimal areas in between the scenario wind directions, where in reality, significant wake losses can be expected. In addition to that, some small deviations of the model due to its complexity affect the optimization outcome significantly, with the current model predicting a maximum farm power production for turbine 2 placement close to the wake of turbine 1. Both of those aspects are weaknesses in the current configuration of the stochastic optimization.

\subsection{Stochastic Optimization:  Expectation Modelling Neural Network}

While the expectation maximization has deemed to be the most accurate depiction of the problem on theoretical level, the previous method used for the resulting stochastic optimzation has shown to be severly limited by computational power, as a large Neural Network is required to model the farm power output both across x and y ranges of the second turbine, as well as across the wind condition variables. 
To overcome these constraints, a alternative formulation is set up, where the Neural Network is designed to output the expected farm power at any x/y point, given a certain wind condition distribution. 



\begin{align}
	\max_{\mathbf{x}, \mathbf{y}} &  \mathbb{E}[f_{Power}(\Delta x, \Delta y) \mid \text{wind condition distribution}]_\text{NN} \\
	\text{s.t.} \quad 
	&  0  \leq \Delta x \leq X_{\max} \\
	&  0  \leq \Delta y \leq Y_{\max} \\
	& \sqrt{(\Delta x)^2 + (\Delta y)^2} \geq d_{\min}
\end{align}

Where:
\begin{itemize}
	\item \( (\Delta x, \Delta y) \) are the relative distances of the two turbines,
	\item \( \mathbb{E}[f_{Power}(\Delta x, \Delta y) \mid \text{wind condition distribution}]_\text{NN}\) a Neural Network that predicts the Expected Farm Power at al \( (\Delta x, \Delta y) \) positions in the parameter space, given a specific wind speed distribution 
	\item \(  X_{\max}, Y_{\max} \) define the maximal distance the two turbines can be placed apart
	\item \( d_{\min} \) is the minimum distance between the two turbines
\end{itemize}

In practice, the new Neural Network configuration is achieved by training the Network directly on the Expected Farm Ppower Values, with the only remaining variables as the relative x/y position of the second wind turbine. The central benefit of this formulation is that the dimensionality of the Neural Network is significantly reduced. The drawback ist that the model is thus condition on a spcific wind condition distribution and can not be used for any other distribution


The Notebook belonging to this formulation can be found in \href{https://github.com/schmeti/uc3m_TFM_wind_farm_optimization_codebase/blob/main/Windfarm_power_modelling/0_two_turbine_problem_constrLearn_probweightedt_expNN.ipynb}{Stochastic optimization with farm power Expectation NN Fomulation Notebook} \cite{schmetz2025twoturbine_stoch2}

\subsubsection{Modelling}

To generate the model with the farm power expectation as output, a more complicated process is required than in the previous formulation. For the Neural Network configuration used in this chapter, the Wind Condition distribution, which in this case will only be the distribution of wind directions, has to be defined. For the chosen distribution a discretization is generated the quantile based method described in Section \ref{subsubsection: discretization}. From this discretization, together with chosen limits for \(\Delta x, \Delta y\), the parameter grid/space is defined and corresponding simulation performed to generate the data set. The probabilities from the wind condition distribution are then joined to the dataset and used to calculate the Expected Farm power for each \(\Delta x, \Delta y\) combination in the parameter grid. This yields a significantly smaller data set with \(\Delta x, \Delta y\) and Expected Farm power as features. This dataset is then used to train a model in the same way done previously, choosing a appropriat configuration of the model which then is used for embedding in the optimization problem. The described steps are shown in Figure \ref{fig:stoch2_model_flow}.


\begin{figure}[h] 
	\centering
	\includegraphics[width=0.8\textwidth]{../figures/optimization/stoch2/stoch2_model_flow.png} 
	\caption{Flowchart displaying the steps used to set up a Neural Network model to model Expected Farm Power across \(\Delta x\) and  \(\Delta y\)}
	\label{fig:stoch2_model_flow}
\end{figure} 

As previously, we proceed to defining the parameter space, with the only difference compared to the previous stochastic formulation is that the wind direction how has variable steplength, using the method presented in Section \ref{subsubsection: discretization}.

\begin{table}[ht]
	\centering
	\caption{Value Ranges for Stochastic Expectation Neural Network Two Turbine Problem Data Set}
	\begin{tabular}{|l|c|c|c|}
		\hline
		\textbf{Variable} & \textbf{Const/Variable} & \textbf{Value} & \textbf{$Steplength$}\\
		\hline
		$\Delta x_{\text{turb2}}$ & Variable & [0, 5000] m & 50 m\\
		$\Delta y_{\text{turb2}}$ & Variable & [0, 500] m  & 50 m\\
		wind\_speed & Constant & 8 m/s & -\\
		wind\_direction & Variable & [180°, 270°]& 35 Quantiles \\
		turbulence\_intensity & Constant & 0.06 & - \\
		\hline
	\end{tabular}
	\label{tab:val_prob2_data}
\end{table}

As at this stage the parameter grid for wind direction is not yet well defined, the wind direction distribution and the number of discretization steps first has to be chosen. For this section, we proceed with the same normal distribution mith mean 260° and standard deviation 10° used in Section \ref{sec:stoch_opti_1}, but now discretized for 35 quantiles as shown in Figure \ref{fig:stoch2_dist}.


\begin{figure}[h] 
	\centering
	\includegraphics[width=0.7\textwidth]{../figures/optimization/stoch2/dist_discret.png} 
	\caption{Quantile based discretized Normal with mean 260° and standard deviation 10°, discretized for 35 quantiles}
	\label{fig:stoch2_dist}
\end{figure} 

With the parameter grid defined, the simulations can be performed, joint with the wind condition probabilities and expectations for the farm power calculated, yielding the dataset to be used in the training of the Neural Network. We thus proceed to the grid search optimization of the Neural Network configuration, as done in the previous chapters. For the distribution shown above, we find the 2-hidden layer and 20 neurons per hidden layer $\text{NN}(5\,{-}\,20^{\times2}\,{-}\,1)$ configuration to yield the best results for least numbers of neurons, as can be seen in Figure \ref{fig:stoch2_NNopti}. 

\textit{We thus proceed with the configuration $\text{NN}(5\,{-}\,20^{\times2}\,{-}\,1)$}.


\begin{figure}[h] 
	\centering
	\includegraphics[width=0.6\textwidth]{../figures/optimization/stoch2/stoch2_NNopti.png} 
	\caption{Grid Search Results for models trained on Farm Power Expectation data, with parameter grid as defined in Table 	\ref{tab:val_prob2_data} and Figure  \ref{fig:stoch2_dist} }
	\label{fig:stoch2_NNopti}
\end{figure} 


The model of configuration $\text{NN}(5\,{-}\,20^{\times2}\,{-}\,1)$ is thus trained and a brief visual inspection performed to investigate how well the model fits the data. As shown in Figure \ref{fig:stoch2_heatmap_inspect_NN}, does the model encorporate the shape of the Expected Power Distribution across x/y fairly well, with the only major deviations near the orgin, e.g. the position of Turbine 1 and directly after Turbine 1 in the principal wind direction. 

\begin{figure}[h] 
	\centering
	\includegraphics[width=1\textwidth]{../figures/optimization/stoch2/stoch2_heatmap_inspect_NN.png} 
	\caption{Visual comparison of training data vs predictions for Neural Network for Expectation of Farm Power, with linear interpolation in between data points to generate heatmap}
	\label{fig:stoch2_heatmap_inspect_NN}
\end{figure} 

The model thus appears to fit the physical behavior suficiently well to be able to proceed to the optimization step. 



\subsubsection{Optimization}

The set up model is thus again embedded into a now seemingly deterministic optimization problem, as the uncertainty has already been taken into account when setting up the Neural Network itself through the expectations. The Neural Network is thus embedded directly into the problem, with the constraints as initially defined. The result shown in Figure \ref{fig:stoch2_opti} yield the expected result, with turbine 2 being placed as far upstream and as far away perpendicularly to the principal wind direction as possible from Wind Turbine 2. 

\begin{figure}[h] 
	\centering
	\includegraphics[width=1\textwidth]{../figures/optimization/stoch2/stoch2_opti.png} 
	\caption{Optimization Result for maximization of Expected Farm Power, with wind direction Normally distributed with mean 260° and standard deviation 10°, discretized into 35 scenarios using quantile based discretization and Neural Network configuration $\text{NN}(5\,{-}\,20^{\times2}\,{-}\,1)$ }
	\label{fig:stoch2_opti}
\end{figure} 

Notably, the solving of this variation optimization problem requires significantly less computational recourses as the previous stochastic formulation, with a significantly larger quantity of scenarios considered for calculating the Expectation. In the entire optimization pipeline, the main limitation is in this formulation constitued by running the simulations required for the individual discretization of different wind direction/wind condition distributions. Due to the efficency of the FLORIS simulations, this does not seem to be a significant limitation for the two turbine configuration at this moment however. Therefore, this method appears to be better fit to scale up the complexity of the wind condition distribution, allowing for expanding to a multivariate distribution of the potentially dependent variables wind direction and wind speed for example. 



\section{Conclusion}\label{chapter:conclusion}

The Paper contains the training of a Neural Network to predict the total farm power/expected farm power generated by a wind farm consisting of two turbines, with the inputs to the model as the relative position of the second wind turbine to the first as well as the wind condition parameters like wind direction. The resulting Neural Networks where embedded into a mixed integer linear programming problem using an approach for decomposing a Neural Network into lmixed-integer inear constraints. Two optimization problems where solved using this aproach, for a stochastic optimizations with a scenario based approach, to maximize the expected power generation, subject to a discreitzed distribution of the wind direction. Here two variants where developed, one via a large general neural network with the wind condition parameters as additional variables and one via a reduced Neural Network, trained on the already evaluated expected farm power for each x/y position of the second turbine. 

The first formulation, using a larger Neural Network indipendent of the wind condition distribution yielded a versatile variant, with a Neural Network that could be applied to any location and any wind condition distribution, while only being able to consider a low number of scenarios due to computational constraints. The second stochastic formulation evaded the computational limitations by training its model directly on the farm power expectations, making both the Neural Network and the optimization model significantly more efficient, but loosing generality due to the Neural Networks conditioning on the wind condistion distribution.

Overall, the second stochastic formulation appears to be the only variant that sufficiently considers the randomness of the wind conditions like wind speed, while showing a path to scaling up computationally.

With the second stochastic formulation having shown to deliver good results, the next steps would revolve around investigating how to generalize the formulation to a larger number of wind turbines. Here, a fundamental reformulation might be required as the current formulation using relative positions would quickly grow the parameter space exponentially. 

None the less it might be worthwile to pursue as the underlying Constraint Learning Methodology has been shown to be able to cope with the complexity of wind turbine wakes in this Thesis.

\begin{thebibliography}{00}

%% For authoryear reference style
%% \bibitem[Author(year)]{label}
%% Text of bibliographic item

\bibitem[European Commission(2023)]{EU_RE_Targets_2023}
European Commission,
\textit{Renewable energy targets},
\url{https://energy.ec.europa.eu/topics/renewable-energy/renewable-energy-directive-targets-and-rules/renewable-energy-targets_en},
2023.
Accessed: 2025-04-03.

\bibitem[Analysis and Research Team(2024)]{ConsiliumEU_Harnessing_Wind_Power_2024}
Analysis and Research Team, General Secretariat of the Council of the European Union,
\textit{Harnessing Wind Power: Navigating the EU Energy Transition and Its Challenges},
\url{https://www.consilium.europa.eu/media/1kyk0wjm/2024_685_art_windpower_web.pdf},
September 2024.
Accessed: 2025-04-03.

\bibitem[European Environment Agency(2009)]{EEA_Wind_Energy_Potential_2009}
European Environment Agency,
\textit{Europe's Onshore and Offshore Wind Energy Potential},
Technical report 6/2009,
\url{https://www.eea.europa.eu/en/analysis/publications/europes-onshore-and-offshore-wind-energy-potential},
2009.
Accessed: 2025-04-03.

\bibitem[Nielsen(2015)]{nielsen2015neuralChap1}
Michael Nielsen,
\textit{Neural Networks and Deep Learning - Chapter 1},
\url{http://neuralnetworksanddeeplearning.com/chap1.html},
2015.
Accessed: 2025-04-10.



\bibitem[Alcántara and Ruiz(2023)]{ALCANTARA2023120895}
Antonio Alcántara and Carlos Ruiz,
\textit{A neural network-based distributional constraint learning methodology for mixed-integer stochastic optimization},
Expert Systems with Applications,
Volume 232,
2023.

\bibitem[Fajemisin et al.(2024)]{FAJEMISIN20241}
Adejuyigbe O. Fajemisin and Donato Maragno and Dick den Hertog,
\textit{Optimization with constraint learning: A framework and survey},
European Journal of Operational Research,
Volume 314,
Number 1,
Pages 1-14,
2024.




\bibitem[Kiranoudis and Maroulis(1997)]{KIRANOUDIS1997439}
C.T. Kiranoudis and Z.B. Maroulis,
\textit{Effective short-cut modelling of wind park efficiency},
Renewable Energy,
Volume 11,
Number 4,
Pages 439-457,
1997.

\bibitem[Magnusson and Smedman(1999)]{MAGNUSSON1999169}
M. Magnusson and A.-S. Smedman,
\textit{Air flow behind wind turbines},
Journal of Wind Engineering and Industrial Aerodynamics,
Volume 80,
Number 1,
Pages 169-189,
1999.

\bibitem[Bortolotti et al.(2019)]{Bortolotti2019}
Pietro Bortolotti and Helena Canet Tarrés and Katherine Dykes and Karl Merz and Latha Sethuraman and David Verelst and Frederik Zahle,
\textit{IEA Wind Task 37 on Systems Engineering in Wind Energy - WP2.1 Reference Wind Turbines},
National Renewable Energy Laboratory,
2019.

\bibitem[Madsen et al.(2022)]{Madsen2022}
Mads Madsen and Frederik Zahle and Sergio Gonzalez Horcas and Thanasis Barlas and Niels Sørensen,
\textit{CFD-based curved tip shape design for wind turbine blades},
Wind Energy Science,
Volume 7,
Pages 1471-1501,
2022.

\bibitem[Kainz et al.(2024)]{Kainz2024IEA}
Samuel Kainz and Julian Quick and Mauricio Souza de Alencar and Sebastian Sanchez Perez Moreno and Katherine Dykes and Christopher Bay and Michiel Zaaijer and Pietro Bortolotti,
\textit{IEA Wind TCP Task 55: The IEA Wind 740-10-MW Reference Offshore Wind Plants},
National Renewable Energy Laboratory,
NREL/TP-5000-87923,
2024.

\bibitem[Birge and Louveaux(1997)]{BirgeLouveauxStochasticProgramming}
John R. Birge and François Louveaux,
\textit{Introduction to Stochastic Programming},
Springer Series in Operations Research and Financial Engineering,
Springer,
1997.



\bibitem[Hou et al.(2019)]{hou_review_2019}
Peng Hou and Jiangsheng Zhu and Kuichao Ma and Guangya Yang and Weihao Hu and Zhe Chen,
\textit{A review of offshore wind farm layout optimization and electrical system design methods},
Journal of Modern Power Systems and Clean Energy,
Volume 7,
Number 5,
Pages 975-986,
2019.

\bibitem[Kim et al.(2024)]{KIM2024123383}
Taewan Kim and Jeonghwan Song and Donghyun You,
\textit{Optimization of a wind farm layout to mitigate the wind power intermittency},
Applied Energy,
Volume 367,
2024.

\bibitem[Azlan et al.(2021)]{AZLAN2021110047}
F. Azlan and J.C. Kurnia and B.T. Tan and M.-Z. Ismadi,
\textit{Review on optimisation methods of wind farm array under three classical wind condition problems},
Renewable and Sustainable Energy Reviews,
Volume 135,
2021.

\bibitem[Wang et al.(2024)]{WANG2024118508}
Li Wang and Mi Dong and Jian Yang and Lei Wang and Sifan Chen and Neven Duić and Young Hoon Joo and Dongran Song,
\textit{Wind turbine wakes modeling and applications: Past, present, and future},
Ocean Engineering,
Volume 309,
2024.

\bibitem[Yang et al.(2023)]{YANG2023119240}
Kun Yang and Xiaowei Deng and Zilong Ti and Shanghui Yang and Senbin Huang and Yuhang Wang,
\textit{A data-driven layout optimization framework of large-scale wind farms based on machine learning},
Renewable Energy,
Volume 218,
2023.

\bibitem[Bempedelis et al.(2024)]{wes-9-869-2024}
N. Bempedelis and F. Gori and A. Wynn and S. Laizet and L. Magri,
\textit{Data-driven optimisation of wind farm layout and wake steering with large-eddy simulations},
Wind Energy Science,
Volume 9,
Number 4,
Pages 869-882,
2024.

\bibitem[Ti et al.(2020)]{TI2020114025}
Zilong Ti and Xiao Wei Deng and Hongxing Yang,
\textit{Wake modeling of wind turbines using machine learning},
Applied Energy,
Volume 257,
2020.

\bibitem[Ti et al.(2021)]{TI2021618}
Zilong Ti and Xiao Wei Deng and Mingming Zhang,
\textit{Artificial Neural Networks based wake model for power prediction of wind farm},
Renewable Energy,
Volume 172,
Pages 618-631,
2021.

\bibitem[Alcántara et al.(2025)]{ALCANTARA2025127876}
Antonio Alcántara and Carlos Ruiz and Calvin Tsay,
\textit{A quantile neural network framework for two-stage stochastic optimization},
Expert Systems with Applications,
2025.

\bibitem[De Raedt et al.(2018)]{de2018learning}
Luc De Raedt and Andrea Passerini and Stefano Teso,
\textit{Learning constraints from examples},
Proceedings of the AAAI conference on artificial intelligence,
Volume 32,
2018.

\bibitem[Bonfietti et al.(2015)]{preprintBonfiettiEmbeddDecisionTrees}
Alessio Bonfietti and Michele Lombardi and Michela Milano,
\textit{Embedding Decision Trees and Random Forests in Constraint Programming},
2015.

\bibitem[de-Alba et al.(2024)]{dealba2024reformulationembeddingneuralnetwork}
Héctor G. -de-Alba and Andres Tellez and Cipriano Santos and Emmanuel Gómez,
\textit{A reformulation to Embedding a Neural Network in a linear program without integer variables},
arXiv:2402.02086,
2024.

\bibitem[Sinner and Fleming(2024)]{Sinner_2024}
Michael Sinner and Paul Fleming,
\textit{Robust wind farm layout optimization},
Journal of Physics: Conference Series,
Volume 2767,
Number 3,
2024.

\bibitem[Glorot et al.(2010)]{preprintReLuGlorot}
Xavier Glorot and Antoine Bordes and Y. Bengio,
\textit{Deep Sparse Rectifier Neural Networks},
Journal of Machine Learning Research,
Volume 15,
2010.

\bibitem[NREL(2025)]{nrel_floris}
National Renewable Energy Laboratory (NREL),
\textit{FLORIS: FLOw Redirection and Induction in Steady State},
GitHub repository,
Version 4.4.2,
\url{https://github.com/NREL/floris},
2025.

\bibitem[NREL(2025)]{nrel_floris_web}
National Renewable Energy Laboratory (NREL),
\textit{FLORIS: FLOw Redirection and Induction in Steady State},
\url{https://www.nrel.gov/wind/floris},
March 2025.

\bibitem[Pedersen et al.(2025)]{dtu_pywake_2025}
Mads M. Pedersen and Paul van der Laan and Mikkel Friis-Møller and Alexander Meyer Forsting and Riccardo Riva and Leonardo Andrés Alcayaga Román and Javier Criado Risco and Julian Quick and Jens Peter Schøler Christiansen and Bjarke Tobias Olsen and Rafael Valotta Rodrigues and Pierre-Elouan Réthoré,
\textit{PyWake: an open-source Python wind farm simulation tool},
\url{https://topfarm.pages.windenergy.dtu.dk/PyWake/},
2025.


\bibitem[Alcantara and Ruiz(2022)]{alcantara_ruiz_distcl_2022_git}
Antonio Alcantara and Carlos Ruiz,
\textit{DistCL: A Neural Network-Based Distributional Constraint Learning tool for Mixed-Integer Stochastic Optimization},
\url{https://github.com/antonioalcantaramata/DistCL},
2022.
Accessed: 2025-06-06.

\bibitem[Schmetz(2025)]{schmetz2025twoturbine_stoch1}
Simon Schmetz,
\textit{Two-Turbine Problem with Constraint Learning and Probability-Weighted Objective},
\url{https://github.com/schmeti/uc3m_TFM_wind_farm_optimization_codebase/blob/main/Windfarm_power_modelling/0_two_turbine_problem_constrLearn_probweighted.ipynb},
2025.
Accessed: 2025-06-06.

\bibitem[Schmetz(2025)]{schmetz2025twoturbine_stoch2}
Simon Schmetz,
\textit{Two-Turbine Problem with Constraint Learning and Probability-Weighted Objective (Expectation Neural Network)},
\url{https://github.com/schmeti/uc3m_TFM_wind_farm_optimization_codebase/blob/main/Windfarm_power_modelling/0_two_turbine_problem_constrLearn_probweightedt_expNN.ipynb},
2025.
Accessed: 2025-06-06.


\end{thebibliography}
\end{document}

\endinput
%%
%% End of file `elsarticle-template-num-names.tex'.
